import streamlit as st
import numpy as np
import cv2
import plotly.graph_objects as go
import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input
from PIL import Image
from streamlit_option_menu import option_menu

# ==============================
# 1ï¸âƒ£ PAGE CONFIG (KhÃ´ng Ä‘á»•i)
# ==============================
st.set_page_config(
    page_title="ğŸŒğŸ‹ Fruit Ripeness Classifier",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================
# 2ï¸âƒ£ CUSTOM CSS (KhÃ´ng Ä‘á»•i)
# ==============================
st.markdown("""
<style>
body {background-color: #0e1117; color: #fafafa;}
.stApp {background-color: #0e1117;}
h1, h2, h3 {color: #00ffb3;}
.uploaded-image {display: flex; justify-content: center; margin-top: 15px;}
.uploaded-image img {
    width: 220px; 
    border-radius: 15px;
    box-shadow: 0px 4px 15px rgba(0, 255, 179, 0.3);
}
.centered {text-align: center;}
</style>
""", unsafe_allow_html=True)

# ==============================
# 3ï¸âƒ£ SIDEBAR MENU (KhÃ´ng Ä‘á»•i)
# ==============================
with st.sidebar:
    selected = option_menu(
        menu_title="ğŸŒ Fruit Ripeness AI Dashboard",
        options=["ğŸ Predict", "â„¹ï¸ About", "â“ Help"],
        icons=["camera", "info-circle", "question-circle"],
        menu_icon="cast",
        default_index=0,
        styles={
            "container": {"background-color": "#111"},
            "icon": {"color": "#00ffb3", "font-size": "22px"},
            "nav-link": {"font-size": "16px", "color": "white", "margin": "5px", "--hover-color": "#00cc8a"},
            "nav-link-selected": {"background-color": "#00ffb3", "color": "black"},
        }
    )

# ==============================
# 4ï¸âƒ£ LOAD MODEL (KhÃ´ng Ä‘á»•i)
# ==============================
@st.cache_resource
def load_fruit_model():
    return load_model("efficientnet_banana_mango.h5", compile=False)

model = load_fruit_model()
classes = ['banana_ripe', 'banana_rotten', 'banana_unripe', 'mango_ripe', 'mango_rotten', 'mango_unripe']

# Giá»¯ tÃªn lá»›p chuáº©n hoáº·c lá»›p báº¡n muá»‘n.
LAST_CONV_LAYER_NAME = 'top_activation' 

# ==============================
# 5ï¸âƒ£ GRAD-CAM FUNCTIONS - Cáº¬P NHáº¬T FIX CUá»I CÃ™NG âœ…
# ==============================
def get_gradcam(model, img_array, last_conv_layer_name=LAST_CONV_LAYER_NAME):
    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)

    try:
        grad_model = Model(
            inputs=model.inputs,
            outputs=[model.get_layer(last_conv_layer_name).output, model.output]
        )
    except ValueError as e:
        st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y lá»›p '{last_conv_layer_name}' trong mÃ´ hÃ¬nh.")
        return None

    with tf.GradientTape() as tape:
        tape.watch(img_tensor) 
        conv_outputs, predictions = grad_model(img_tensor)
        
        class_index = tf.cast(tf.argmax(predictions[0]), dtype=tf.int32) 
        loss = tf.gather(predictions[0], class_index) 

    grads = tape.gradient(loss, conv_outputs)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))

    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0.0)

    # Chuáº©n hÃ³a (Normalize)
    max_val = tf.reduce_max(heatmap)
    
    # ğŸŒŸ Cáº¢I THIá»†N Xá»¬ LÃ HEATMAP Yáº¾U
    if max_val < 1e-5:
        # Náº¿u heatmap quÃ¡ yáº¿u (gáº§n nhÆ° toÃ n 0), Ã¡p dá»¥ng ká»¹ thuáº­t chuáº©n hÃ³a máº¡nh hÆ¡n 
        # (VÃ­ dá»¥: chuáº©n hÃ³a báº±ng tá»•ng hoáº·c má»™t giÃ¡ trá»‹ epsilon)
        
        heatmap = heatmap / (tf.reduce_sum(heatmap) + 1e-6)
        # Chuáº©n hÃ³a láº¡i theo max value cá»§a heatmap má»›i (sau khi chia cho sum)
        max_val_new = tf.reduce_max(heatmap)
        if max_val_new > 0:
             heatmap = heatmap / max_val_new
    elif max_val > 1e-10:
        heatmap /= max_val
    
    return heatmap.numpy()


def overlay_gradcam(original_img, heatmap, alpha=0.4):
    heatmap_resized = cv2.resize(heatmap, (original_img.size[0], original_img.size[1]))
    heatmap_uint8 = np.uint8(255 * heatmap_resized)
    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(np.array(original_img), 1 - alpha, heatmap_color, alpha, 0)
    return Image.fromarray(overlay), heatmap_resized

# ==============================
# 6ï¸âƒ£ PAGE: PREDICT - Cáº¬P NHáº¬T LOGIC CONTOUR âœ…
# ==============================
if selected == "ğŸ Predict":
    st.title("ğŸŒğŸ‹ Fruit Ripeness Prediction")
    st.write("Upload an image of a banana or mango and let the AI predict its ripeness!")

    uploaded_file = st.file_uploader("ğŸ“¸ Upload an image", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        img = Image.open(uploaded_file).convert("RGB")
        st.markdown('<div class="uploaded-image">', unsafe_allow_html=True)
        st.image(img, caption="ğŸ–¼ï¸ Uploaded Image", use_container_width=False)
        st.markdown('</div>', unsafe_allow_html=True)

        # Preprocess
        img_resized = img.resize((224, 224))
        img_array = image.img_to_array(img_resized)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = preprocess_input(img_array)

        # Predict
        with st.spinner("ğŸ” AI Ä‘ang phÃ¢n tÃ­ch..."):
            preds = model.predict(img_array)
            preds = np.array(preds)
            class_index = int(np.argmax(preds[0]))
            class_name = classes[class_index]
            confidence = np.max(preds[0])

        st.success(f"âœ… **Prediction:** {class_name}")
        st.progress(float(confidence))
        st.write(f"**Confidence:** {confidence * 100:.2f}%")

        # --- Top 3 predictions bar chart (KhÃ´ng Ä‘á»•i) ---
        top3_idx = np.argsort(preds[0])[::-1][:3]
        top3_classes = [classes[i] for i in top3_idx]
        top3_scores = [preds[0][i] for i in top3_idx]
        fig = go.Figure(go.Bar(
            x=top3_scores,
            y=top3_classes,
            orientation="h",
            marker_color=["#00ffb3", "#00cc99", "#009977"]
        ))
        fig.update_layout(
            title="ğŸ“Š Top-3 Predictions",
            xaxis_title="Confidence",
            template="plotly_dark",
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)

        # --- Grad-CAM if rotten ---
        if "rotten" in class_name.lower():
            st.subheader("ğŸ”¥ Grad-CAM Visualization (Rotten Areas)")
            
            heatmap = get_gradcam(model, img_array)
            
            if heatmap is not None and np.max(heatmap) > 0.0: # Kiá»ƒm tra láº§n cuá»‘i Heatmap cÃ³ dá»¯ liá»‡u khÃ´ng
                overlay_img, heatmap_resized = overlay_gradcam(img, heatmap)
                
                col1, col2 = st.columns(2)

                with col1:
                    st.image(overlay_img, caption="Grad-CAM Overlay (VÃ¹ng AI táº­p trung)", use_container_width=True)

                # --- Contour overlay for highlighting rotten areas ---
                
                heatmap_uint8 = np.uint8(255 * heatmap_resized)
                
                # 2. ğŸŒŸ GIáº¢M LÃ€M Má»œ: Chá»‰ (5, 5) Ä‘á»ƒ giá»¯ láº¡i chi tiáº¿t hÆ¡n
                heatmap_blurry = cv2.GaussianBlur(heatmap_uint8, (5, 5), 0) 
                
                # 3. ğŸŒŸ Háº  NGÆ¯á» NG Ráº¤T THáº¤P (0.2): Äá»ƒ báº¯t Ä‘Æ°á»£c tÃ­n hiá»‡u yáº¿u
                threshold_val = int(255 * 0.2) 
                _, thresh = cv2.threshold(heatmap_blurry, threshold_val, 255, cv2.THRESH_BINARY) 
                
                # 4. TÃ¬m cÃ¡c Ä‘Æ°á»ng viá»n
                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                # 5. Váº½ Ä‘Æ°á»ng viá»n lÃªn áº£nh gá»‘c
                contour_img_cv = np.array(img.copy())
                cv2.drawContours(contour_img_cv, contours, -1, (255, 0, 0), 2) 
                
                contour_final_img = Image.fromarray(contour_img_cv)

                with col2:
                    st.image(contour_final_img, caption="VÃ¹ng bá»‹ thá»‘i (Contour Äá»)", use_container_width=True)
            else:
                 st.warning("âš ï¸ MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n lÃ  'rotten', nhÆ°ng Heatmap khÃ´ng cÃ³ dá»¯ liá»‡u (ráº¥t yáº¿u), cÃ³ thá»ƒ do Ä‘áº·c Ä‘iá»ƒm quÃ¡ khÃ¡c biá»‡t so vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n.")

        else:
            st.info("ğŸ’¡ Grad-CAM chá»‰ hiá»ƒn thá»‹ khi dá»± Ä‘oÃ¡n lÃ  **'rotten'** Ä‘á»ƒ khoanh vÃ¹ng khu vá»±c bá»‹ thá»‘i.")

    else:
        st.info("â¬†ï¸ Please upload an image to start prediction.")

# ==============================
# 7ï¸âƒ£ ABOUT (KhÃ´ng Ä‘á»•i)
# ==============================
elif selected == "â„¹ï¸ About":
    st.title("â„¹ï¸ About This App")
    st.markdown("""
    **Fruit Ripeness Classifier** â€” EfficientNetB0 
    
    * Sá»­ dá»¥ng máº¡ng nÆ¡-ron **EfficientNetB0** (Ä‘Ã£ Ä‘Æ°á»£c fine-tune).
    * Há»— trá»£ **Chuá»‘i** ğŸŒ vÃ  **XoÃ i** ğŸ¥­ (3 giai Ä‘oáº¡n má»—i loáº¡i: **ripe**, **unripe**, **rotten**).
    * Sá»­ dá»¥ng thuáº­t toÃ¡n **Grad-CAM** Ä‘á»ƒ giáº£i thÃ­ch (eXplainable AI - XAI), lÃ m ná»•i báº­t vÃ¹ng áº£nh quan trá»ng nháº¥t dáº«n Ä‘áº¿n káº¿t quáº£ dá»± Ä‘oÃ¡n (Ä‘áº·c biá»‡t lÃ  vÃ¹ng bá»‹ thá»‘i).
    """)

# ==============================
# 8ï¸âƒ£ HELP (KhÃ´ng Ä‘á»•i)
# ==============================
elif selected == "â“ Help":
    st.title("â“ How to Use")
    st.markdown("""
    1ï¸âƒ£ Äi Ä‘áº¿n tab **ğŸ Predict** vÃ  táº£i lÃªn má»™t hÃ¬nh áº£nh (chuá»‘i hoáº·c xoÃ i).
    
    2ï¸âƒ£ Xem 3 lá»›p dá»± Ä‘oÃ¡n hÃ ng Ä‘áº§u vÃ  Ä‘á»™ tin cáº­y.
    
    3ï¸âƒ£ Náº¿u lá»›p dá»± Ä‘oÃ¡n lÃ  **rotten** (bá»‹ thá»‘i) â†’ **Grad-CAM** sáº½ tá»± Ä‘á»™ng xuáº¥t hiá»‡n. 
    
    * **áº¢nh Overlay (Heatmap):** VÃ¹ng mÃ u Ä‘á»/vÃ ng lÃ  vÃ¹ng áº£nh cÃ³ áº£nh hÆ°á»Ÿng **máº¡nh nháº¥t** Ä‘áº¿n quyáº¿t Ä‘á»‹nh "rotten" cá»§a AI.
    * **áº¢nh Contour (Khoanh vÃ¹ng):** Sá»­ dá»¥ng Ä‘Æ°á»ng viá»n mÃ u **Äá»** Ä‘á»ƒ khoanh vÃ¹ng khu vá»±c "thá»‘i" quan trá»ng nháº¥t theo nháº­n Ä‘á»‹nh cá»§a Grad-CAM.
    """)